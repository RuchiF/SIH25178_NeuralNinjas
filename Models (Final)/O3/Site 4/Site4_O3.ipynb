{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEzUHsPgsOZx",
        "outputId": "5fafd36a-acec-44a2-f185-4a87bd655bdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, joblib, time\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "use_gpu=False\n",
        "BASE = Path(\".\")\n",
        "MODEL_DIR = BASE / \"models\"\n",
        "PLOT_DIR = BASE / \"plots\"\n",
        "MODEL_DIR.mkdir(exist_ok=True)\n",
        "PLOT_DIR.mkdir(exist_ok=True)\n",
        "SAVE_DIR=Path(\"models\")\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)"
      ],
      "metadata": {
        "id": "ekno_7W7vF4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, json, joblib, time\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# XGBoost and Keras\n",
        "import xgboost as xgb\n",
        "# from xgboost import callback as xgb_callback # Import xgb_callback - Not used if early_stopping_rounds is direct parameter\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "\n",
        "\n",
        "\n",
        "def find_top_correlated_features(df, target_col='O3_target', top_n=70, save_path='top_features.json'):\n",
        "    \"\"\"\n",
        "    Find top N features most correlated with target column FROM ENGINEERED FEATURES.\n",
        "    Call this AFTER create_features() to select from all lag/roll features.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : DataFrame\n",
        "        DataFrame with ALL engineered features (lags, rolls, etc.)\n",
        "    target_col : str\n",
        "        Name of target column (e.g., 'NO2_target' or 'O3_target')\n",
        "    top_n : int\n",
        "        Number of top correlated features to return\n",
        "    save_path : str or Path\n",
        "        Path to save the selected features as JSON\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    dict : Dictionary with target_col as key and list of top features\n",
        "    \"\"\"\n",
        "\n",
        "    df = df.copy()\n",
        "\n",
        "    # Define columns to exclude from feature selection\n",
        "    exclude_cols = {\"year\", \"month\", \"day\", \"hour\", \"datetime\", \"day_of_week\"}\n",
        "\n",
        "    # Get all potential feature columns (exclude time columns and other targets)\n",
        "    candidate_features = [\n",
        "        c for c in df.columns\n",
        "        if c not in exclude_cols\n",
        "        and c != target_col\n",
        "        and not (c.endswith(\"_target\") and c != target_col)  # Exclude other targets\n",
        "    ]\n",
        "\n",
        "    # Check if target exists\n",
        "    if target_col not in df.columns:\n",
        "        raise ValueError(f\"Target column '{target_col}' not found in dataframe\")\n",
        "\n",
        "    # Calculate correlations\n",
        "    correlations = {}\n",
        "    for feature in candidate_features:\n",
        "        if feature in df.columns:\n",
        "            # Calculate correlation, handling NaN values\n",
        "            valid_mask = df[feature].notna() & df[target_col].notna()\n",
        "            if valid_mask.sum() > 0:\n",
        "                corr = df.loc[valid_mask, feature].corr(df.loc[valid_mask, target_col])\n",
        "                if not np.isnan(corr):\n",
        "                    correlations[feature] = abs(corr)  # Use absolute correlation\n",
        "\n",
        "    # Sort by correlation and get top N\n",
        "    sorted_features = sorted(correlations.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_features = [feat for feat, corr in sorted_features[:top_n]]\n",
        "\n",
        "    # Print results\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Top {top_n} Features Correlated with {target_col}\")\n",
        "    print(f\"Total engineered features: {len(candidate_features)}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"{'Rank':<6} {'Feature':<40} {'|Correlation|':<15}\")\n",
        "    print(f\"={'--'*35}\")\n",
        "\n",
        "    for i, (feat, corr) in enumerate(sorted_features[:top_n], 1):\n",
        "        print(f\"{i:<6} {feat:<40} {corr:<15.4f}\")\n",
        "\n",
        "    print(f\"{'--'*35}\\n\")\n",
        "\n",
        "    # Save to JSON\n",
        "    result = {target_col: top_features}\n",
        "\n",
        "    with open(save_path, 'w') as f:\n",
        "        json.dump(result, f, indent=2)\n",
        "\n",
        "    print(f\"✓ Top features saved to: {save_path}\")\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def load_site_csv(path):\n",
        "    \"\"\"Load and sort CSV by datetime\"\"\"\n",
        "    df = pd.read_csv(path)\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "    for c in ['year','month','day','hour']:\n",
        "        if c not in df.columns:\n",
        "            raise KeyError(f\"Missing required column: {c}\")\n",
        "\n",
        "    # Create datetime and sort\n",
        "    df['datetime'] = pd.to_datetime(\n",
        "        df['year'].astype(int).astype(str) + '-' +\n",
        "        df['month'].astype(int).astype(str) + '-' +\n",
        "        df['day'].astype(int).astype(str) + ' ' +\n",
        "        df['hour'].astype(int).astype(str) + ':00:00'\n",
        "    )\n",
        "    df.sort_values('datetime', inplace=True)\n",
        "    df = df.reset_index(drop=True)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "# Removed apply_gap_aware_features as its logic will be handled inline with create_features\n",
        "# and then robustly filled with ffill and training medians in predict_unseen.\n",
        "def create_features(df, use_calibrated=True, target_cols_present=True):\n",
        "    \"\"\"\n",
        "    Basic feature engineering. Creates all features, including lags and rolls for targets.\n",
        "    Columns will always be created, even if initial values are NaN.\n",
        "    \"\"\"\n",
        "\n",
        "    df = df.copy()\n",
        "\n",
        "    # -----------------------------------\n",
        "    # 0. Ensure datetime exists and sort\n",
        "    # ---------------------------------\n",
        "    if \"datetime\" not in df.columns:\n",
        "        df[\"datetime\"] = pd.to_datetime(\n",
        "            df[\"year\"].astype(int).astype(str) + \"-\" +\n",
        "            df[\"month\"].astype(int).astype(str) + \"-\" +\n",
        "            df[\"day\"].astype(int).astype(str) + \" \" +\n",
        "            df[\"hour\"].astype(int).astype(str) + \":00:00\"\n",
        "        )\n",
        "        df.sort_values(\"datetime\", inplace=True)\n",
        "        df = df.reset_index(drop=True)\n",
        "    else:\n",
        "        df = df.sort_values(\"datetime\").reset_index(drop=True)\n",
        "\n",
        "    # -----------------------------------\n",
        "    # 1. Fill daily satellite values\n",
        "    # -----------------------------------\n",
        "    for col in [\"NO2_satellite\", \"HCHO_satellite\", \"ratio_satellite\"]:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].ffill().bfill()\n",
        "\n",
        "    # -----------------------------------\n",
        "    # 2. Cyclical time features\n",
        "    # -----------------------------------\n",
        "    df[\"hour_sin\"] = np.sin(2 * np.pi * df[\"hour\"] / 24)\n",
        "    df[\"hour_cos\"] = np.cos(2 * np.pi * df[\"hour\"] / 24)\n",
        "\n",
        "    df[\"month_sin\"] = np.sin(2 * np.pi * df[\"month\"] / 12)\n",
        "    df[\"month_cos\"] = np.cos(2 * np.pi * df[\"month\"] / 12)\n",
        "\n",
        "    df[\"day_of_week\"] = df[\"datetime\"].dt.dayofweek\n",
        "    df[\"is_weekend\"] = (df[\"day_of_week\"] >= 5).astype(int)\n",
        "\n",
        "    # -----------------------------------\n",
        "    # 3. BLH Transformations and Domain Features\n",
        "    # -----------------------------------\n",
        "    if \"blh_forecast\" in df.columns:\n",
        "        df['blh_forecast_log'] = np.log1p(df['blh_forecast'])\n",
        "        date_keys = df[\"year\"].astype(str) + \"-\" + df[\"month\"].astype(str) + \"-\" + df[\"day\"].astype(str)\n",
        "        df['blh_daily_min'] = df.groupby(date_keys)['blh_forecast'].transform('min')\n",
        "        df['blh_daily_max'] = df.groupby(date_keys)['blh_forecast'].transform('max')\n",
        "        df['blh_daily_range'] = df['blh_daily_max'] - df['blh_daily_min']\n",
        "\n",
        "    # -----------------------------------\n",
        "    # 4. Forecast columns (calibrated preferred)\n",
        "    # -----------------------------------\n",
        "    base = [c for c in df.columns if c.endswith(\"_forecast\") and not c.endswith(\"_forecast_cal\")]\n",
        "    cal  = [c for c in df.columns if c.endswith(\"_forecast_cal\")]\n",
        "\n",
        "    forecast_cols = cal if (use_calibrated and len(cal) > 0) else base\n",
        "\n",
        "    # -----------------------------------\n",
        "    # 5. Standard Lags & rolling windows\n",
        "    # -----------------------------------\n",
        "    feature_lags = [1, 3, 6, 12, 24]\n",
        "\n",
        "    cols_for_lags = forecast_cols + [\n",
        "        c for c in df.columns if c.startswith('blh_forecast_log') or c.startswith('blh_daily')\n",
        "    ]\n",
        "    for col in [\"NO2_satellite\", \"HCHO_satellite\", \"ratio_satellite\"]:\n",
        "        if col in df.columns and col not in cols_for_lags:\n",
        "            cols_for_lags.append(col)\n",
        "\n",
        "    cols_for_lags = list(set(cols_for_lags))\n",
        "\n",
        "    for col in cols_for_lags:\n",
        "        if col in df.columns:\n",
        "            for lag in feature_lags:\n",
        "                df[f\"{col}_lag{lag}\"] = df[col].shift(lag)\n",
        "            for window in [3, 6, 12]:\n",
        "                df[f\"{col}_roll{window}\"] = df[col].rolling(window=window, min_periods=1).mean()\n",
        "\n",
        "    # -----------------------------------\n",
        "    # 6. Lags for target (autoregression)\n",
        "    # -----------------------------------\n",
        "    # 6. Lags for target (autoregression) - UPDATED LOGIC\n",
        "    # -----------------------------------\n",
        "    target_lags = [24, 36, 48, 72]\n",
        "\n",
        "    for pol in [\"O3\", \"NO2\"]:\n",
        "        t = f\"{pol}_target\"\n",
        "        if t in df.columns:\n",
        "            # Create dynamic shift based on hour\n",
        "            for base_lag in target_lags:\n",
        "                # For each row, shift by (hour + 1)\n",
        "                shifted_values = []\n",
        "                for idx in range(len(df)):\n",
        "                    current_hour = df.loc[idx, 'hour']\n",
        "                    shift_amount = current_hour + 1\n",
        "\n",
        "                    # Get the value from shift_amount positions back\n",
        "                    if idx - shift_amount >= 0:\n",
        "                        shifted_values.append(df.loc[idx - shift_amount, t])\n",
        "                    else:\n",
        "                        shifted_values.append(np.nan)\n",
        "\n",
        "                df[f\"{t}_lag{base_lag}\"] = shifted_values\n",
        "\n",
        "            # Rolling windows with dynamic shift\n",
        "            for window in [3, 6, 12]:\n",
        "                rolled_values = []\n",
        "                for idx in range(len(df)):\n",
        "                    current_hour = df.loc[idx, 'hour']\n",
        "                    shift_amount = current_hour + 1\n",
        "\n",
        "                    # Get window starting from shift_amount positions back\n",
        "                    if idx - shift_amount >= 0:\n",
        "                        start_idx = max(0, idx - shift_amount - window + 1)\n",
        "                        end_idx = idx - shift_amount + 1\n",
        "                        window_vals = df.loc[start_idx:end_idx-1, t]\n",
        "                        rolled_values.append(window_vals.mean())\n",
        "                    else:\n",
        "                        rolled_values.append(np.nan)\n",
        "\n",
        "                df[f\"{t}_roll{window}\"] = rolled_values\n",
        "\n",
        "\n",
        "\n",
        "     # Interaction features\n",
        "    if \"T_forecast\" in df.columns and \"u_forecast\" in df.columns:\n",
        "        df[\"T_x_u\"] = df[\"T_forecast\"] * df[\"u_forecast\"]\n",
        "    if \"blh_forecast\" in df.columns:\n",
        "        df[\"blh_x_hour_sin\"] = df[\"blh_forecast\"] * df[\"hour_sin\"]\n",
        "        df[\"blh_x_hour_cos\"] = df[\"blh_forecast\"] * df[\"hour_cos\"]\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "def find_top_correlated_features(df, target_col='O3_target', top_n=30, save_path='top_features.json'):\n",
        "    \"\"\"Find top N correlated features.\"\"\"\n",
        "    df = df.copy()\n",
        "    exclude_cols = {\"year\", \"month\", \"day\", \"hour\", \"datetime\", \"day_of_week\"}\n",
        "\n",
        "    candidate_features = [\n",
        "        c for c in df.columns\n",
        "        if c not in exclude_cols\n",
        "        and c != target_col\n",
        "        and not (c.endswith(\"_target\") and c != target_col)\n",
        "    ]\n",
        "\n",
        "    if target_col not in df.columns:\n",
        "        raise ValueError(f\"Target column '{target_col}' not found\")\n",
        "\n",
        "    correlations = {}\n",
        "    for feature in candidate_features:\n",
        "        if feature in df.columns:\n",
        "            valid_mask = df[feature].notna() & df[target_col].notna()\n",
        "            if valid_mask.sum() > 0:\n",
        "                corr = df.loc[valid_mask, feature].corr(df.loc[valid_mask, target_col])\n",
        "                if not np.isnan(corr):\n",
        "                    correlations[feature] = abs(corr)\n",
        "\n",
        "    sorted_features = sorted(correlations.items(), key=lambda x: x[1], reverse=True)\n",
        "    top_features = [feat for feat, corr in sorted_features[:top_n]]\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Top {top_n} Features Correlated with {target_col}\")\n",
        "    print(f\"Total engineered features: {len(candidate_features)}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"{'Rank':<6} {'Feature':<40} {'|Correlation|':<15}\")\n",
        "    print(f\"{'-'*70}\")\n",
        "\n",
        "    for i, (feat, corr) in enumerate(sorted_features[:top_n], 1):\n",
        "        print(f\"{i:<6} {feat:<40} {corr:<15.4f}\")\n",
        "\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    result = {target_col: top_features}\n",
        "    with open(save_path, 'w') as f:\n",
        "        json.dump(result, f, indent=2)\n",
        "\n",
        "    print(f\"✓ Top features saved to: {save_path}\")\n",
        "    return result\n",
        "\n",
        "\n",
        "def prepare_features_and_target_unified(df, target_col, selected_features=None):\n",
        "    \"\"\"\n",
        "    UNIFIED preprocessing - identical to inference pipeline.\n",
        "    Saves ALL medians (target + column medians) for exact replication during inference.\n",
        "    \"\"\"\n",
        "\n",
        "    exclude = {\"year\", \"month\", \"day\", \"hour\", \"datetime\", \"day_of_week\"}\n",
        "\n",
        "    if selected_features is not None:\n",
        "        feature_cols = selected_features\n",
        "    else:\n",
        "        feature_cols = [c for c in df.columns if c not in exclude and not c.endswith(\"_target\")]\n",
        "\n",
        "    # Get available features\n",
        "    available_features = [c for c in feature_cols if c in df.columns]\n",
        "    X = df[available_features].select_dtypes(include=[np.number])\n",
        "    y = df[target_col]\n",
        "\n",
        "    # Time-based split (NO SHUFFLE)\n",
        "    split_idx = int(len(df) * 0.8)\n",
        "    X_train = X.iloc[:split_idx].copy()\n",
        "    X_test  = X.iloc[split_idx:].copy()\n",
        "    y_train = y.iloc[:split_idx].copy()\n",
        "    y_test  = y.iloc[split_idx:].copy()\n",
        "\n",
        "    # ================================================\n",
        "    # UNIFIED IMPUTATION STRATEGY (same as inference)\n",
        "    # ================================================\n",
        "\n",
        "    # 1. Calculate training target median\n",
        "    if target_col in df.columns:\n",
        "        target_values = df[target_col].dropna()\n",
        "        if len(target_values) > 0:\n",
        "            training_target_median = target_values.median()\n",
        "        else:\n",
        "            training_target_median = 0.0\n",
        "    else:\n",
        "        training_target_median = 0.0\n",
        "\n",
        "    print(f\"\\n✓ Training target median: {training_target_median:.2f}\")\n",
        "\n",
        "    # 2. Calculate column medians for ALL features\n",
        "    column_medians = {}\n",
        "    for col in X_train.columns:\n",
        "        col_median = X_train[col].median()\n",
        "        column_medians[col] = float(col_median if pd.notna(col_median) else 0.0)\n",
        "\n",
        "    print(f\"✓ Calculated medians for {len(column_medians)} features\")\n",
        "\n",
        "    # 3. Save ALL medians for inference\n",
        "    median_info = {\n",
        "        'target_median': float(training_target_median),\n",
        "        'target_col': target_col,\n",
        "        'column_medians': column_medians  # Save all column medians\n",
        "    }\n",
        "\n",
        "    median_path = MODEL_DIR / 'training_medians.json'\n",
        "    with open(median_path, 'w') as f:\n",
        "        json.dump(median_info, f, indent=2)\n",
        "\n",
        "    print(f\"✓ Saved medians to: {median_path}\")\n",
        "\n",
        "    # 4. Impute training data\n",
        "    for col in X_train.columns:\n",
        "        if 'target' in col.lower():\n",
        "            X_train[col] = X_train[col].fillna(training_target_median)\n",
        "        else:\n",
        "            X_train[col] = X_train[col].fillna(column_medians[col])\n",
        "\n",
        "    # 5. Impute test data (using training statistics)\n",
        "    for col in X_test.columns:\n",
        "        if 'target' in col.lower():\n",
        "            X_test[col] = X_test[col].fillna(training_target_median)\n",
        "        else:\n",
        "            X_test[col] = X_test[col].fillna(column_medians[col])\n",
        "\n",
        "    # 6. Scale features\n",
        "    scaler = RobustScaler()\n",
        "    X_train_s = pd.DataFrame(\n",
        "        scaler.fit_transform(X_train),\n",
        "        columns=X_train.columns,\n",
        "        index=X_train.index\n",
        "    )\n",
        "    X_test_s = pd.DataFrame(\n",
        "        scaler.transform(X_test),\n",
        "        columns=X_test.columns,\n",
        "        index=X_test.index\n",
        "    )\n",
        "\n",
        "    # Save scaler and feature_cols\n",
        "    joblib.dump(scaler, MODEL_DIR / 'scaler.joblib')\n",
        "    with open(MODEL_DIR / 'feature_cols.json', 'w') as f:\n",
        "        json.dump(X_train.columns.tolist(), f, indent=2)\n",
        "\n",
        "    return X_train_s, X_test_s, y_train, y_test, scaler, X_train.columns.tolist()\n",
        "# ---------- (END reuse) ----------\n",
        "\n",
        "# --- Utility functions used below ---\n",
        "def ria_score(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Refined Index of Agreement (d1).\n",
        "    d1 = 1 - sum((P_i - O_i)^2) / sum((|P_i - O_bar| + |O_i - O_bar|)^2)\n",
        "    \"\"\"\n",
        "    y_true = np.asarray(y_true)\n",
        "    y_pred = np.asarray(y_pred)\n",
        "    o_bar = np.mean(y_true)\n",
        "    num = np.sum((y_pred - y_true) ** 2)\n",
        "    denom = np.sum((np.abs(y_pred - o_bar) + np.abs(y_true - o_bar)) ** 2)\n",
        "    if denom == 0:\n",
        "        return np.nan\n",
        "    return 1.0 - (num / denom)\n",
        "\n",
        "def evaluate_all(y_true, y_pred, prefix=\"Model\"):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    ria = ria_score(y_true, y_pred)\n",
        "    print(f\"{prefix} -> RMSE: {rmse:.4f}  |  R2: {r2:.4f}  |  RIA: {ria:.4f}\")\n",
        "    return {\"rmse\": rmse, \"r2\": r2, \"ria\": ria}\n",
        "\n",
        "def build_sequences_for_gru(X_train_s, X_test_s, y_train, y_test, seq_len=24):\n",
        "    \"\"\"\n",
        "    Build sequences for training and testing the GRU.\n",
        "    For test sequences we prefix with tail of train so that first test rows have context.\n",
        "    \"\"\"\n",
        "    X_train_arr = X_train_s.values\n",
        "    y_train_arr = y_train.values\n",
        "    n_features = X_train_arr.shape[1]\n",
        "    # Build train sequences\n",
        "    if len(X_train_arr) < seq_len:\n",
        "        raise ValueError(\"Not enough train rows to build train sequences with seq_len.\")\n",
        "    X_tr_seq = []\n",
        "    y_tr_seq = []\n",
        "    for i in range(seq_len - 1, len(X_train_arr)):\n",
        "        X_tr_seq.append(X_train_arr[i - seq_len + 1:i + 1])\n",
        "        y_tr_seq.append(y_train_arr[i])\n",
        "    X_tr_seq = np.asarray(X_tr_seq)\n",
        "    y_tr_seq = np.asarray(y_tr_seq)\n",
        "\n",
        "    # Build test sequences:\n",
        "    # prefix with last (seq_len-1) rows of train so the sliding windows are valid\n",
        "    prefix = X_train_arr[-(seq_len - 1):] if seq_len > 1 else np.empty((0, n_features))\n",
        "    X_test_prefixed = np.vstack([prefix, X_test_s.values])\n",
        "    y_test_arr = y_test.values\n",
        "\n",
        "    X_te_seq = []\n",
        "    y_te_seq = []\n",
        "    # sequences should align so that there are len(y_test) sequences (one per test row)\n",
        "    for i in range(seq_len - 1, len(X_test_prefixed)):\n",
        "        # Only collect those sequences whose rightmost index corresponds to test region\n",
        "        # The index in prefixed array where rightmost index >= len(prefix)\n",
        "        if i - (seq_len - 1) >= 0 and (i - (len(prefix))) < len(y_test_arr):\n",
        "            X_te_seq.append(X_test_prefixed[i - seq_len + 1:i + 1])\n",
        "            # the corresponding y is test y at position (i - len(prefix))\n",
        "            y_te_seq.append(y_test_arr[i - len(prefix)])\n",
        "    X_te_seq = np.asarray(X_te_seq)\n",
        "    y_te_seq = np.asarray(y_te_seq)\n",
        "\n",
        "    return X_tr_seq, y_tr_seq, X_te_seq, y_te_seq\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# MAIN TRAINING PIPELINE\n",
        "# ============================================================\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TRAINING DATA PREPROCESSING (UNIFIED WITH INFERENCE)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# 1. Load raw data\n",
        "df = load_site_csv(\"site_4_train_data.csv\")\n",
        "print(f\"Raw data shape: {df.shape}\")\n",
        "\n",
        "# 2. Feature engineering\n",
        "df_engineered = create_features(df, use_calibrated=True, target_cols_present=True)\n",
        "print(f\"Engineered data shape: {df_engineered.shape}\")\n",
        "\n",
        "# 3. Select top 30 features\n",
        "top_features_dict = find_top_correlated_features(\n",
        "    df_engineered,\n",
        "    target_col='O3_target',\n",
        "    top_n=30,\n",
        "    save_path='top_features_o3.json'\n",
        ")\n",
        "selected_features = top_features_dict['O3_target']\n",
        "\n",
        "# 4. Prepare data with UNIFIED preprocessing\n",
        "X_train_s, X_test_s, y_train, y_test, scaler, feature_cols = \\\n",
        "    prepare_features_and_target_unified(df_engineered, \"O3_target\", selected_features=selected_features)\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"FINAL RESULTS:\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Train shape: {X_train_s.shape}\")\n",
        "print(f\"Test shape:  {X_test_s.shape}\")\n",
        "print(f\"Features used: {len(feature_cols)}\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "# Verify no NaNs remain\n",
        "print(\"Data quality check:\")\n",
        "print(f\"  Train NaNs: {X_train_s.isna().sum().sum()}\")\n",
        "print(f\"  Test NaNs:  {X_test_s.isna().sum().sum()}\")\n",
        "print(f\"  Train target NaNs: {y_train.isna().sum()}\")\n",
        "print(f\"  Test target NaNs:  {y_test.isna().sum()}\")\n",
        "\n",
        "if X_train_s.isna().sum().sum() > 0 or X_test_s.isna().sum().sum() > 0:\n",
        "    print(\"\\n⚠ WARNING: NaN values remain in data!\")\n",
        "else:\n",
        "    print(\"\\n✓ All data clean - ready for training\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PREPROCESSING SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "print(\"✓ Identical imputation strategy as inference\")\n",
        "print(\"✓ Target features → training target median\")\n",
        "print(\"✓ Other features → their column medians from training\")\n",
        "print(\"✓ All medians saved to training_medians.json\")\n",
        "print(\"✓ Inference will load and use exact same values\")\n",
        "print(\"=\"*70)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFSQUFRDWcee",
        "outputId": "615e96c7-d8a0-44f4-8e1f-cb4c8a0cf14a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "TRAINING DATA PREPROCESSING (UNIFIED WITH INFERENCE)\n",
            "======================================================================\n",
            "Raw data shape: (24505, 18)\n",
            "Engineered data shape: (24505, 165)\n",
            "\n",
            "======================================================================\n",
            "Top 30 Features Correlated with O3_target\n",
            "Total engineered features: 157\n",
            "======================================================================\n",
            "Rank   Feature                                  |Correlation|  \n",
            "----------------------------------------------------------------------\n",
            "1      hour_cos                                 0.4168         \n",
            "2      hour_sin                                 0.4008         \n",
            "3      O3_target_roll12                         0.3993         \n",
            "4      O3_target_roll6                          0.3065         \n",
            "5      O3_target_roll3                          0.2753         \n",
            "6      O3_target_lag24                          0.2461         \n",
            "7      O3_target_lag36                          0.2461         \n",
            "8      O3_target_lag48                          0.2461         \n",
            "9      O3_target_lag72                          0.2461         \n",
            "10     blh_x_hour_sin                           0.2409         \n",
            "11     blh_x_hour_cos                           0.2390         \n",
            "12     month_cos                                0.2312         \n",
            "13     month_sin                                0.1410         \n",
            "14     O3_forecast_roll6                        0.1284         \n",
            "15     O3_forecast_lag24                        0.1284         \n",
            "16     O3_forecast_roll3                        0.1280         \n",
            "17     O3_forecast_lag1                         0.1272         \n",
            "18     O3_forecast_roll12                       0.1268         \n",
            "19     O3_forecast                              0.1267         \n",
            "20     O3_forecast_lag3                         0.1262         \n",
            "21     O3_forecast_lag6                         0.1205         \n",
            "22     O3_forecast_lag12                        0.1160         \n",
            "23     w_forecast_roll12                        0.1119         \n",
            "24     NO2_target_lag24                         0.1108         \n",
            "25     NO2_target_lag36                         0.1108         \n",
            "26     NO2_target_lag48                         0.1108         \n",
            "27     NO2_target_lag72                         0.1108         \n",
            "28     w_forecast_roll6                         0.1098         \n",
            "29     w_forecast_lag24                         0.1082         \n",
            "30     w_forecast_roll3                         0.1081         \n",
            "======================================================================\n",
            "\n",
            "✓ Top features saved to: top_features_o3.json\n",
            "\n",
            "✓ Training target median: 31.20\n",
            "✓ Calculated medians for 30 features\n",
            "✓ Saved medians to: models/training_medians.json\n",
            "\n",
            "======================================================================\n",
            "FINAL RESULTS:\n",
            "======================================================================\n",
            "Train shape: (19604, 30)\n",
            "Test shape:  (4901, 30)\n",
            "Features used: 30\n",
            "======================================================================\n",
            "\n",
            "Data quality check:\n",
            "  Train NaNs: 0\n",
            "  Test NaNs:  0\n",
            "  Train target NaNs: 0\n",
            "  Test target NaNs:  0\n",
            "\n",
            "✓ All data clean - ready for training\n",
            "\n",
            "======================================================================\n",
            "PREPROCESSING SUMMARY\n",
            "======================================================================\n",
            "✓ Identical imputation strategy as inference\n",
            "✓ Target features → training target median\n",
            "✓ Other features → their column medians from training\n",
            "✓ All medians saved to training_medians.json\n",
            "✓ Inference will load and use exact same values\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# 2) Train GRU model (SEQUENCES ONLY – NO XGBOOST)\n",
        "# =========================================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks\n",
        "\n",
        "SEQ_LEN=24\n",
        "print(\"\\n--- Building sequences for GRU ---\")\n",
        "\n",
        "X_tr_seq, y_tr_seq, X_te_seq, y_te_seq = build_sequences_for_gru(\n",
        "    X_train_s, X_test_s, y_train, y_test, seq_len=SEQ_LEN\n",
        ")\n",
        "\n",
        "print(f\"GRU Seq shapes -> train: {X_tr_seq.shape}, test: {X_te_seq.shape}\")\n",
        "\n",
        "n_features = X_tr_seq.shape[2]\n",
        "\n",
        "\n",
        "def build_gru_model(seq_len, n_features):\n",
        "    inp = layers.Input(shape=(seq_len, n_features))\n",
        "    x = layers.Masking(mask_value=0.0)(inp)\n",
        "    x = layers.GRU(128, return_sequences=True, use_cudnn=False)(x) # Added use_cudnn=False\n",
        "    x = layers.GRU(64, return_sequences=False, use_cudnn=False)(x) # Added use_cudnn=False\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    x = layers.Dense(32, activation=\"relu\")(x)\n",
        "    out = layers.Dense(1, activation=\"linear\")(x)\n",
        "\n",
        "    model = models.Model(inputs=inp, outputs=out)\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "        loss=\"mse\",\n",
        "        metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "gru_model = build_gru_model(SEQ_LEN, n_features)\n",
        "gru_model.summary()\n",
        "\n",
        "# Callbacks\n",
        "es = callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=15,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "rlr = callbacks.ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\",\n",
        "    factor=0.5,\n",
        "    patience=6\n",
        ")\n",
        "\n",
        "# Train\n",
        "history = gru_model.fit(\n",
        "    X_tr_seq, y_tr_seq,\n",
        "    validation_data=(X_te_seq, y_te_seq),\n",
        "    epochs=200,\n",
        "    batch_size=128,\n",
        "    callbacks=[es, rlr],\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "# Save model\n",
        "gru_model.save(SAVE_DIR / \"gru_model.keras\")\n",
        "print(\"Saved GRU model.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uT8WPuieO7Wh",
        "outputId": "8f8a45f9-a639-4c1e-e31e-bed301a6cc5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Building sequences for GRU ---\n",
            "GRU Seq shapes -> train: (19581, 24, 30), test: (4901, 24, 30)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m30\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m30\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ masking (\u001b[38;5;33mMasking\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m30\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ any (\u001b[38;5;33mAny\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m61,440\u001b[0m │ masking[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
              "│                     │                   │            │ any[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m37,248\u001b[0m │ gru[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│                     │                   │            │ any[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ gru_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m2,080\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ masking (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Masking</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ any (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Any</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">61,440</span> │ masking[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
              "│                     │                   │            │ any[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,248</span> │ gru[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│                     │                   │            │ any[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ gru_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m100,801\u001b[0m (393.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,801</span> (393.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m100,801\u001b[0m (393.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100,801</span> (393.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "153/153 - 13s - 85ms/step - loss: 1721.9537 - root_mean_squared_error: 41.4964 - val_loss: 1419.3612 - val_root_mean_squared_error: 37.6744 - learning_rate: 1.0000e-03\n",
            "Epoch 2/200\n",
            "153/153 - 2s - 15ms/step - loss: 1005.6092 - root_mean_squared_error: 31.7113 - val_loss: 575.0971 - val_root_mean_squared_error: 23.9812 - learning_rate: 1.0000e-03\n",
            "Epoch 3/200\n",
            "153/153 - 2s - 16ms/step - loss: 440.1540 - root_mean_squared_error: 20.9798 - val_loss: 441.8022 - val_root_mean_squared_error: 21.0191 - learning_rate: 1.0000e-03\n",
            "Epoch 4/200\n",
            "153/153 - 1s - 9ms/step - loss: 366.0468 - root_mean_squared_error: 19.1324 - val_loss: 418.5159 - val_root_mean_squared_error: 20.4577 - learning_rate: 1.0000e-03\n",
            "Epoch 5/200\n",
            "153/153 - 1s - 8ms/step - loss: 325.2431 - root_mean_squared_error: 18.0345 - val_loss: 359.8749 - val_root_mean_squared_error: 18.9704 - learning_rate: 1.0000e-03\n",
            "Epoch 6/200\n",
            "153/153 - 1s - 8ms/step - loss: 303.8500 - root_mean_squared_error: 17.4313 - val_loss: 391.8273 - val_root_mean_squared_error: 19.7946 - learning_rate: 1.0000e-03\n",
            "Epoch 7/200\n",
            "153/153 - 1s - 8ms/step - loss: 284.9315 - root_mean_squared_error: 16.8799 - val_loss: 357.5102 - val_root_mean_squared_error: 18.9079 - learning_rate: 1.0000e-03\n",
            "Epoch 8/200\n",
            "153/153 - 1s - 9ms/step - loss: 267.7778 - root_mean_squared_error: 16.3639 - val_loss: 396.9943 - val_root_mean_squared_error: 19.9247 - learning_rate: 1.0000e-03\n",
            "Epoch 9/200\n",
            "153/153 - 1s - 8ms/step - loss: 256.3812 - root_mean_squared_error: 16.0119 - val_loss: 435.7617 - val_root_mean_squared_error: 20.8749 - learning_rate: 1.0000e-03\n",
            "Epoch 10/200\n",
            "153/153 - 1s - 8ms/step - loss: 247.2666 - root_mean_squared_error: 15.7247 - val_loss: 443.1440 - val_root_mean_squared_error: 21.0510 - learning_rate: 1.0000e-03\n",
            "Epoch 11/200\n",
            "153/153 - 1s - 10ms/step - loss: 230.7941 - root_mean_squared_error: 15.1919 - val_loss: 513.3124 - val_root_mean_squared_error: 22.6564 - learning_rate: 1.0000e-03\n",
            "Epoch 12/200\n",
            "153/153 - 2s - 10ms/step - loss: 216.1587 - root_mean_squared_error: 14.7023 - val_loss: 513.9334 - val_root_mean_squared_error: 22.6701 - learning_rate: 1.0000e-03\n",
            "Epoch 13/200\n",
            "153/153 - 2s - 15ms/step - loss: 203.5191 - root_mean_squared_error: 14.2660 - val_loss: 520.6210 - val_root_mean_squared_error: 22.8171 - learning_rate: 1.0000e-03\n",
            "Epoch 14/200\n",
            "153/153 - 1s - 8ms/step - loss: 182.0378 - root_mean_squared_error: 13.4921 - val_loss: 487.8002 - val_root_mean_squared_error: 22.0862 - learning_rate: 5.0000e-04\n",
            "Epoch 15/200\n",
            "153/153 - 1s - 8ms/step - loss: 170.6428 - root_mean_squared_error: 13.0630 - val_loss: 568.5027 - val_root_mean_squared_error: 23.8433 - learning_rate: 5.0000e-04\n",
            "Epoch 16/200\n",
            "153/153 - 1s - 8ms/step - loss: 164.8400 - root_mean_squared_error: 12.8390 - val_loss: 616.8105 - val_root_mean_squared_error: 24.8357 - learning_rate: 5.0000e-04\n",
            "Epoch 17/200\n",
            "153/153 - 1s - 8ms/step - loss: 159.3261 - root_mean_squared_error: 12.6224 - val_loss: 638.9388 - val_root_mean_squared_error: 25.2772 - learning_rate: 5.0000e-04\n",
            "Epoch 18/200\n",
            "153/153 - 1s - 8ms/step - loss: 153.1173 - root_mean_squared_error: 12.3741 - val_loss: 628.8322 - val_root_mean_squared_error: 25.0765 - learning_rate: 5.0000e-04\n",
            "Epoch 19/200\n",
            "153/153 - 1s - 8ms/step - loss: 147.8107 - root_mean_squared_error: 12.1577 - val_loss: 635.8854 - val_root_mean_squared_error: 25.2168 - learning_rate: 5.0000e-04\n",
            "Epoch 20/200\n",
            "153/153 - 2s - 10ms/step - loss: 140.6112 - root_mean_squared_error: 11.8580 - val_loss: 675.5334 - val_root_mean_squared_error: 25.9910 - learning_rate: 2.5000e-04\n",
            "Epoch 21/200\n",
            "153/153 - 2s - 10ms/step - loss: 134.7960 - root_mean_squared_error: 11.6102 - val_loss: 682.7359 - val_root_mean_squared_error: 26.1292 - learning_rate: 2.5000e-04\n",
            "Epoch 22/200\n",
            "153/153 - 2s - 15ms/step - loss: 130.1161 - root_mean_squared_error: 11.4068 - val_loss: 679.9608 - val_root_mean_squared_error: 26.0761 - learning_rate: 2.5000e-04\n",
            "Saved GRU model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "# --- 1. Generate Predictions ---\n",
        "print(\"Generating predictions...\")\n",
        "y_pred = gru_model.predict(X_te_seq, verbose=0)\n",
        "\n",
        "# --- 2. Prepare True Values ---\n",
        "y_true = y_te_seq.reshape(-1, 1)\n",
        "\n",
        "# --- 3. Calculate Metrics ---\n",
        "\n",
        "# A. RMSE\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "\n",
        "# B. R2 Score\n",
        "r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "# C. RMSE % (Relative to Mean)\n",
        "actual_mean = np.mean(y_true)\n",
        "rmse_percentage = (rmse / actual_mean) * 100\n",
        "\n",
        "# D. RIA (Reliability Index of Agreement / Modified IOA)\n",
        "def calculate_ria(y_true, y_pred):\n",
        "    y_true_f = y_true.flatten()\n",
        "    y_pred_f = y_pred.flatten()\n",
        "    mean_true = np.mean(y_true_f)\n",
        "\n",
        "    numerator = np.sum(np.abs(y_pred_f - y_true_f))\n",
        "    denominator = np.sum(np.abs(y_pred_f - mean_true) + np.abs(y_true_f - mean_true))\n",
        "\n",
        "    if denominator == 0: return 0.0\n",
        "    return 1.0 - (numerator / denominator)\n",
        "\n",
        "ria = calculate_ria(y_true, y_pred)\n",
        "\n",
        "# --- 4. Print Results ---\n",
        "print(f\"\\n{'='*30}\")\n",
        "print(f\"GRU MODEL EVALUATION\")\n",
        "print(f\"{'='*30}\")\n",
        "print(f\"RMSE:           {rmse:.4f}\")\n",
        "print(f\"R² Score:       {r2:.4f}\")\n",
        "print(f\"RMSE % (Mean):  {rmse_percentage:.2f}%\")\n",
        "print(f\"RIA Score:      {ria:.4f}\")\n",
        "print(f\"{'='*30}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c67hWIubw3rs",
        "outputId": "ff45b8fa-ec2c-4486-da59-9a9799df0412"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating predictions...\n",
            "\n",
            "==============================\n",
            "GRU MODEL EVALUATION\n",
            "==============================\n",
            "RMSE:           18.9079\n",
            "R² Score:       0.7479\n",
            "RMSE % (Mean):  45.04%\n",
            "RIA Score:      0.7764\n",
            "==============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# 1. Plot the scatter\n",
        "plt.scatter(y_true, y_pred, alpha=0.3)\n",
        "\n",
        "# 2. Define limits for the unity line (y=x)\n",
        "# Log scales error on 0, so we ensure the start point is slightly > 0\n",
        "# If your data is strictly > 0, you can use .min(). If it has 0s, use 1e-1 or 1.\n",
        "min_val = max(y_true.min(), 1e-1)\n",
        "max_val = y_true.max()\n",
        "\n",
        "# 3. Plot the perfect prediction line (y=x)\n",
        "plt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)\n",
        "\n",
        "# 4. Set scales to Logarithmic\n",
        "plt.xscale('log')\n",
        "plt.yscale('log')\n",
        "\n",
        "# 5. Labels and Grid\n",
        "plt.xlabel('True Values (log scale)')\n",
        "plt.ylabel('Predictions (log scale)')\n",
        "plt.title('True vs. Predicted Values (Log-Log)')\n",
        "\n",
        "# 'both' ensures grid lines appear for minor ticks (helpful in log plots)\n",
        "plt.grid(True, which=\"both\", ls=\"-\", alpha=0.5)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Q4VVFP4Z2WwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you stored the fit result in a variable named 'history' or 'history_lstm'\n",
        "# e.g., history = model.fit(...)\n",
        "\n",
        "def plot_training_curves(history):\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history.get('val_loss') # Use .get() in case validation split wasn't used\n",
        "\n",
        "    epochs = range(1, len(loss) + 1)\n",
        "\n",
        "    plt.figure(figsize=(14, 6))\n",
        "\n",
        "    # --- Plot 1: Loss (MSE) ---\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, loss, 'y', label='Training Loss')\n",
        "    if val_loss:\n",
        "        plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss (MSE)')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "\n",
        "    # --- Plot 2: Additional Metrics (if present, e.g., MAE) ---\n",
        "    # Check if 'mae' or 'mean_absolute_error' is in the history\n",
        "    if 'mae' in history.history:\n",
        "        mae = history.history['mae']\n",
        "        val_mae = history.history.get('val_mae')\n",
        "\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(epochs, mae, 'y', label='Training MAE')\n",
        "        if val_mae:\n",
        "            plt.plot(epochs, val_mae, 'r', label='Validation MAE')\n",
        "        plt.title('Training and Validation MAE')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Mean Absolute Error')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Run the function (Replace 'history_lstm' with your actual variable name if different)\n",
        "# If your previous cell was: history_lstm = model_cnn_lstm.fit(...)\n",
        "plot_training_curves(history)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "Pkl8KMIcj0T8",
        "outputId": "0b42ee83-00e2-44c3-9511-2923cc8f1d95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import joblib\n",
        "import json\n",
        "from pathlib import Path\n",
        "from datetime import timedelta\n",
        "\n",
        "\"\"\"\n",
        "INFERENCE WITH UNIFIED PREPROCESSING\n",
        "\n",
        "Loads ALL medians saved during training:\n",
        "- target_median: For target-related features\n",
        "- column_medians: For each non-target feature\n",
        "\n",
        "This ensures IDENTICAL preprocessing between training and inference.\n",
        "\"\"\"\n",
        "\n",
        "# =========================================================\n",
        "# Load Model and Preprocessing\n",
        "# =========================================================\n",
        "\n",
        "SAVE_DIR = Path(\"models\")\n",
        "SEQ_LEN = 24\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"LOADING TRAINED MODEL\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Need to define build_gru_model here for loading weights\n",
        "def build_gru_model(seq_len, n_features):\n",
        "    inp = tf.keras.layers.Input(shape=(seq_len, n_features))\n",
        "    x = tf.keras.layers.Masking(mask_value=0.0)(inp)\n",
        "    x = tf.keras.layers.GRU(128, return_sequences=True, use_cudnn=False)(x) # Added use_cudnn=False\n",
        "    x = tf.keras.layers.GRU(64, return_sequences=False, use_cudnn=False)(x) # Added use_cudnn=False\n",
        "    x = tf.keras.layers.Dropout(0.2)(x)\n",
        "    x = tf.keras.layers.Dense(32, activation=\"relu\")(x)\n",
        "    out = tf.keras.layers.Dense(1, activation=\"linear\")(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=inp, outputs=out)\n",
        "    # Compile is not strictly necessary for loading weights, but good practice if you want to continue training\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "        loss=\"mse\",\n",
        "        metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "scaler = joblib.load(SAVE_DIR / \"scaler.joblib\")\n",
        "with open(SAVE_DIR / \"feature_cols.json\", \"r\") as f:\n",
        "    feature_cols = json.load(f)\n",
        "\n",
        "# Instantiate model architecture with use_cudnn=False explicitly\n",
        "n_features_model = len(feature_cols)\n",
        "gru_model = build_gru_model(SEQ_LEN, n_features_model)\n",
        "# Load only the weights into the newly built model\n",
        "gru_model.load_weights(SAVE_DIR / \"gru_model.keras\") # .keras saves weights and architecture\n",
        "\n",
        "# Load saved medians from training\n",
        "with open(SAVE_DIR / \"training_medians.json\", \"r\") as f:\n",
        "    median_info = json.load(f)\n",
        "    training_target_median = median_info['target_median']\n",
        "    column_medians = median_info['column_medians']\n",
        "\n",
        "print(f\"✓ Loaded model, scaler, and {len(feature_cols)} features\")\n",
        "print(f\"✓ Loaded training medians:\")\n",
        "print(f\"  - Target median: {training_target_median:.2f}\")\n",
        "print(f\"  - Column medians: {len(column_medians)} features\")\n",
        "\n",
        "# Display features\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"FEATURES REQUIRED ({len(feature_cols)} total)\")\n",
        "print(\"=\"*70)\n",
        "target_feats = [f for f in feature_cols if 'target' in f.lower()]\n",
        "other_feats = [f for f in feature_cols if 'target' not in f.lower()]\n",
        "print(f\"Target-dependent: {len(target_feats)}\")\n",
        "print(f\"Other features: {len(other_feats)}\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "\n",
        "def load_site_csv(path):\n",
        "    \"\"\"Load CSV with datetime.\"\"\"\n",
        "    df = pd.read_csv(path)\n",
        "    df.columns = [c.strip() for c in df.columns]\n",
        "    for c in ['year','month','day','hour']:\n",
        "        if c not in df.columns:\n",
        "            raise KeyError(f\"Missing: {c}\")\n",
        "    df['datetime'] = pd.to_datetime(\n",
        "        df['year'].astype(int).astype(str) + '-' +\n",
        "        df['month'].astype(int).astype(str) + '-' +\n",
        "        df['day'].astype(int).astype(str) + ' ' +\n",
        "        df['hour'].astype(int).astype(str) + ':00:00'\n",
        "    )\n",
        "    df.sort_values('datetime', inplace=True)\n",
        "    df = df.reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "def build_history_lookup(df_train):\n",
        "    \"\"\"Create datetime -> O3_target lookup.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"BUILDING HISTORY LOOKUP\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    if 'O3_target' not in df_train.columns:\n",
        "        print(\"⚠ O3_target not found\")\n",
        "        return {}\n",
        "\n",
        "    history_lookup = {}\n",
        "    for idx, row in df_train.iterrows():\n",
        "        dt = row['datetime']\n",
        "        value = row['O3_target']\n",
        "        if pd.notna(value):\n",
        "            history_lookup[dt] = value\n",
        "\n",
        "    print(f\"✓ Built lookup: {len(history_lookup)} entries\")\n",
        "    if history_lookup:\n",
        "        print(f\"  Range: {min(history_lookup.keys())} to {max(history_lookup.keys())}\")\n",
        "\n",
        "    return history_lookup\n",
        "\n",
        "\n",
        "def predict_with_history_buffer(df_unseen, history_lookup, gru_model, scaler,\n",
        "                                feature_cols, training_target_median, column_medians, seq_len=24):\n",
        "    \"\"\"\n",
        "    Smart prediction with UNIFIED preprocessing (same as training).\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"PREDICTING WITH UNIFIED PREPROCESSING\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"Using training medians:\")\n",
        "    print(f\"  Target median: {training_target_median:.2f} µg/m³\")\n",
        "    print(f\"  Column medians: {len(column_medians)} features\")\n",
        "\n",
        "    # Initialize\n",
        "    prediction_buffer = {}\n",
        "    df_work = df_unseen.copy()\n",
        "    # The target column in df_work should be the one being predicted, which is 'O3_target'\n",
        "    # The error message from build_history_lookup indicated 'NO2_target'. This should align.\n",
        "    # For this task, we are predicting 'O3_target', so 'NO2_target' should not be present in df_work.\n",
        "    # Let's remove this line if it's not strictly necessary or change to O3_target if it is.\n",
        "    # For now, assuming O3_target as per `target_col='O3_target'` in training.\n",
        "    # Let's adjust `build_history_lookup` to dynamically use the `target_col` provided\n",
        "    # or ensure it's robust.\n",
        "    # The current `build_history_lookup` function has 'NO2_target' hardcoded. This needs adjustment.\n",
        "    # However, the current problem is with GRU prediction masking, let's address that first.\n",
        "\n",
        "    # Correcting the target column being predicted\n",
        "    target_col_name = median_info['target_col'] # Get the actual target column name from saved info\n",
        "    df_work[target_col_name] = np.nan # Initialize the target column for prediction\n",
        "\n",
        "    predictions = []\n",
        "\n",
        "    stats = {\n",
        "        'from_training': 0,\n",
        "        'from_predictions': 0,\n",
        "        'median_filled': 0\n",
        "    }\n",
        "\n",
        "    print(f\"\\nProcessing {len(df_work)} rows...\\n\")\n",
        "\n",
        "    for idx in range(len(df_work)):\n",
        "        current_datetime = df_work.loc[idx, 'datetime']\n",
        "        current_hour = df_work.loc[idx, 'hour']\n",
        "        shift_amount = current_hour + 1\n",
        "\n",
        "        # ==========================================\n",
        "        # Compute lag features for the target_col_name\n",
        "        # ==========================================\n",
        "        target_lags = [24, 36, 48, 72]\n",
        "\n",
        "        for lag in target_lags:\n",
        "            lag_datetime = current_datetime - timedelta(hours=shift_amount)\n",
        "\n",
        "            # Check if this lag feature is actually in feature_cols before trying to set it\n",
        "            if f'{target_col_name}_lag{lag}' in feature_cols:\n",
        "                if lag_datetime in history_lookup:\n",
        "                    lag_value = history_lookup[lag_datetime]\n",
        "                    stats['from_training'] += 1\n",
        "                elif lag_datetime in prediction_buffer:\n",
        "                    lag_value = prediction_buffer[lag_datetime]\n",
        "                    stats['from_predictions'] += 1\n",
        "                else:\n",
        "                    lag_value = training_target_median\n",
        "                    stats['median_filled'] += 1\n",
        "\n",
        "                df_work.loc[idx, f'{target_col_name}_lag{lag}'] = lag_value\n",
        "\n",
        "        # ==========================================\n",
        "        # Compute rolling features for the target_col_name\n",
        "        # ==========================================\n",
        "        for window in [3, 6, 12]:\n",
        "            if f'{target_col_name}_roll{window}' in feature_cols: # Check if roll feature is used\n",
        "                window_values = []\n",
        "\n",
        "                for w in range(window):\n",
        "                    look_datetime = current_datetime - timedelta(hours=shift_amount + w)\n",
        "\n",
        "                    if look_datetime in history_lookup:\n",
        "                        window_values.append(history_lookup[look_datetime])\n",
        "                        stats['from_training'] += 1\n",
        "                    elif look_datetime in prediction_buffer:\n",
        "                        window_values.append(prediction_buffer[look_datetime])\n",
        "                        stats['from_predictions'] += 1\n",
        "                    else:\n",
        "                        window_values.append(training_target_median)\n",
        "                        stats['median_filled'] += 1\n",
        "\n",
        "                if len(window_values) > 0:\n",
        "                    df_work.loc[idx, f'{target_col_name}_roll{window}'] = np.mean(window_values)\n",
        "                else:\n",
        "                    df_work.loc[idx, f'{target_col_name}_roll{window}'] = training_target_median\n",
        "\n",
        "        # ==========================================\n",
        "        # Prepare features (UNIFIED with training)\n",
        "        # ==========================================\n",
        "\n",
        "        # Get available features\n",
        "        available_cols = [f for f in feature_cols if f in df_work.columns]\n",
        "        X_current = df_work.loc[[idx], available_cols].select_dtypes(include=[np.number])\n",
        "\n",
        "        # Add missing features\n",
        "        for feat in feature_cols:\n",
        "            if feat not in X_current.columns:\n",
        "                if 'target' in feat.lower():\n",
        "                    X_current[feat] = training_target_median\n",
        "                else:\n",
        "                    X_current[feat] = column_medians.get(feat, 0.0)\n",
        "\n",
        "        # Reorder to match training\n",
        "        X_current = X_current[feature_cols]\n",
        "\n",
        "        # Fill any NaNs using EXACT same logic as training\n",
        "        for col in X_current.columns:\n",
        "            if pd.isna(X_current[col].iloc[0]):\n",
        "                if 'target' in col.lower():\n",
        "                    # Use training target median\n",
        "                    X_current.loc[X_current.index[0], col] = training_target_median\n",
        "                else:\n",
        "                    # Use saved column median from training\n",
        "                    X_current.loc[X_current.index[0], col] = column_medians.get(col, 0.0)\n",
        "\n",
        "        # Verify shape\n",
        "        if X_current.shape[1] != len(feature_cols):\n",
        "            raise ValueError(f\"Shape mismatch: {X_current.shape[1]} vs {len(feature_cols)}\")\n",
        "\n",
        "        # Scale\n",
        "        X_current_scaled = scaler.transform(X_current)\n",
        "\n",
        "        # ==========================================\n",
        "        # Build sequence\n",
        "        # ==========================================\n",
        "\n",
        "        if idx < seq_len:\n",
        "            pad_length = seq_len - idx - 1\n",
        "\n",
        "            if idx == 0:\n",
        "                X_seq = np.zeros((1, seq_len, len(feature_cols)))\n",
        "                X_seq[0, -1, :] = X_current_scaled[0]\n",
        "            else:\n",
        "                prev_features = df_work.iloc[max(0, idx-seq_len+1):idx+1]\n",
        "\n",
        "                # Build previous features with required columns\n",
        "                prev_feat_df = pd.DataFrame(index=prev_features.index)\n",
        "                for feat in feature_cols:\n",
        "                    if feat in prev_features.columns:\n",
        "                        prev_feat_df[feat] = prev_features[feat]\n",
        "                    else:\n",
        "                        if 'target' in feat.lower():\n",
        "                            prev_feat_df[feat] = training_target_median\n",
        "                        else:\n",
        "                            prev_feat_df[feat] = column_medians.get(feat, 0.0)\n",
        "\n",
        "                # Fill NaNs with appropriate medians\n",
        "                for col in prev_feat_df.columns:\n",
        "                    if 'target' in col.lower():\n",
        "                        prev_feat_df[col] = prev_feat_df[col].fillna(training_target_median)\n",
        "                    else:\n",
        "                        prev_feat_df[col] = prev_feat_df[col].fillna(column_medians.get(col, 0.0))\n",
        "\n",
        "                prev_scaled = scaler.transform(prev_feat_df)\n",
        "\n",
        "                if pad_length > 0:\n",
        "                    X_seq = np.vstack([\n",
        "                        np.zeros((pad_length, len(feature_cols))),\n",
        "                        prev_scaled\n",
        "                    ])\n",
        "                else:\n",
        "                    X_seq = prev_scaled[-seq_len:]\n",
        "\n",
        "                X_seq = X_seq.reshape(1, seq_len, len(feature_cols))\n",
        "        else:\n",
        "            # Corrected slice: we need seq_len rows ending at idx, which is [idx-seq_len+1 : idx+1]\n",
        "            prev_features = df_work.iloc[idx-seq_len+1:idx+1] # This slice now correctly selects seq_len rows\n",
        "\n",
        "            # Build with required columns\n",
        "            prev_feat_df = pd.DataFrame(index=prev_features.index)\n",
        "            for feat in feature_cols:\n",
        "                if feat in prev_features.columns:\n",
        "                    prev_feat_df[feat] = prev_features[feat]\n",
        "                else:\n",
        "                    if 'target' in feat.lower():\n",
        "                        prev_feat_df[feat] = training_target_median\n",
        "                    else:\n",
        "                        prev_feat_df[feat] = column_medians.get(feat, 0.0)\n",
        "\n",
        "            # Fill NaNs\n",
        "            for col in prev_feat_df.columns:\n",
        "                if 'target' in col.lower():\n",
        "                    prev_feat_df[col] = prev_feat_df[col].fillna(training_target_median)\n",
        "                else:\n",
        "                    prev_feat_df[col] = prev_feat_df[col].fillna(column_medians.get(col, 0.0))\n",
        "\n",
        "            prev_scaled = scaler.transform(prev_feat_df)\n",
        "            X_seq = prev_scaled.reshape(1, seq_len, len(feature_cols))\n",
        "\n",
        "        # ==========================================\n",
        "        # Predict\n",
        "        # ==========================================\n",
        "\n",
        "        pred = gru_model.predict(X_seq, verbose=0)[0, 0]\n",
        "        predictions.append(pred)\n",
        "        prediction_buffer[current_datetime] = pred\n",
        "\n",
        "        if (idx + 1) % 500 == 0:\n",
        "            print(f\"  {idx + 1}/{len(df_work)} rows...\")\n",
        "\n",
        "    print(f\"✓ Completed\\n\")\n",
        "\n",
        "    # Statistics\n",
        "    total = sum(stats.values())\n",
        "    print(\"=\"*70)\n",
        "    print(\"LOOKUP STATISTICS\")\n",
        "    print(\"=\"*70)\n",
        "    print(f\"  Training data:  {stats['from_training']:6d} ({stats['from_training']/total*100:5.1f}%)\")\n",
        "    print(f\"  Past predictions: {stats['from_predictions']:6d} ({stats['from_predictions']/total*100:5.1f}%)\")\n",
        "    print(f\"  Median-filled:  {stats['median_filled']:6d} ({stats['median_filled']/total*100:5.1f}%)\")\n",
        "    print(f\"Total lookups: {total}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "\n",
        "def create_unseen_features(df_unseen, history_lookup, use_calibrated=True):\n",
        "    \"\"\"\n",
        "    Apply feature engineering to unseen data. This is a simplified version\n",
        "    that primarily sets up the datetime and fills satellite data, as the\n",
        "    lag/roll for target are handled in the prediction loop.\n",
        "    \"\"\"\n",
        "    df = df_unseen.copy()\n",
        "\n",
        "    # -----------------------------------\n",
        "    # 0. Ensure datetime exists and sort\n",
        "    # ---------------------------------\n",
        "    if \"datetime\" not in df.columns:\n",
        "        df[\"datetime\"] = pd.to_datetime(\n",
        "            df[\"year\"].astype(int).astype(str) + \"-\" +\n",
        "            df[\"month\"].astype(int).astype(str) + \"-\" +\n",
        "            df[\"day\"].astype(int).astype(str) + \" \" +\n",
        "            df[\"hour\"].astype(int).astype(str) + \":00:00\"\n",
        "        )\n",
        "        df.sort_values(\"datetime\", inplace=True)\n",
        "        df = df.reset_index(drop=True)\n",
        "    else:\n",
        "        df = df.sort_values(\"datetime\").reset_index(drop=True)\n",
        "\n",
        "    # -----------------------------------\n",
        "    # 1. Fill daily satellite values\n",
        "    # -----------------------------------\n",
        "    for col in [\"NO2_satellite\", \"HCHO_satellite\", \"ratio_satellite\"]:\n",
        "        if col in df.columns:\n",
        "            df[col] = df[col].ffill().bfill()\n",
        "\n",
        "    # -----------------------------------\n",
        "    # 2. Cyclical time features\n",
        "    # -----------------------------------\n",
        "    df[\"hour_sin\"] = np.sin(2 * np.pi * df[\"hour\"] / 24)\n",
        "    df[\"hour_cos\"] = np.cos(2 * np.pi * df[\"hour\"] / 24)\n",
        "\n",
        "    df[\"month_sin\"] = np.sin(2 * np.pi * df[\"month\"] / 12)\n",
        "    df[\"month_cos\"] = np.cos(2 * np.pi * df[\"month\"] / 12)\n",
        "\n",
        "    df[\"day_of_week\"] = df[\"datetime\"].dt.dayofweek\n",
        "    df[\"is_weekend\"] = (df[\"day_of_week\"] >= 5).astype(int)\n",
        "\n",
        "    # -----------------------------------\n",
        "    # 3. BLH Transformations and Domain Features\n",
        "    # -----------------------------------\n",
        "    if \"blh_forecast\" in df.columns:\n",
        "        df['blh_forecast_log'] = np.log1p(df['blh_forecast'])\n",
        "        date_keys = df[\"year\"].astype(str) + \"-\" + df[\"month\"].astype(str) + \"-\" + df[\"day\"].astype(str)\n",
        "        df['blh_daily_min'] = df.groupby(date_keys)['blh_forecast'].transform('min')\n",
        "        df['blh_daily_max'] = df.groupby(date_keys)['blh_forecast'].transform('max')\n",
        "        df['blh_daily_range'] = df['blh_daily_max'] - df['blh_daily_min']\n",
        "\n",
        "    # -----------------------------------\n",
        "    # 4. Forecast columns (calibrated preferred)\n",
        "    # -----------------------------------\n",
        "    base = [c for c in df.columns if c.endswith(\"_forecast\") and not c.endswith(\"_forecast_cal\")]\n",
        "    cal  = [c for c in df.columns if c.endswith(\"_forecast_cal\")]\n",
        "\n",
        "    forecast_cols = cal if (use_calibrated and len(cal) > 0) else base\n",
        "\n",
        "    # -----------------------------------\n",
        "    # 5. Standard Lags & rolling windows\n",
        "    # -----------------------------------\n",
        "    feature_lags = [1, 3, 6, 12, 24]\n",
        "\n",
        "    cols_for_lags = forecast_cols + [\n",
        "        c for c in df.columns if c.startswith('blh_forecast_log') or c.startswith('blh_daily')\n",
        "    ]\n",
        "    for col in [\"NO2_satellite\", \"HCHO_satellite\", \"ratio_satellite\"]:\n",
        "        if col in df.columns and col not in cols_for_lags:\n",
        "            cols_for_lags.append(col)\n",
        "\n",
        "    cols_for_lags = list(set(cols_for_lags))\n",
        "\n",
        "    for col in cols_for_lags:\n",
        "        if col in df.columns:\n",
        "            for lag in feature_lags:\n",
        "                df[f\"{col}_lag{lag}\"] = df[col].shift(lag)\n",
        "            for window in [3, 6, 12]:\n",
        "                df[f\"{col}_roll{window}\"] = df[col].rolling(window=window, min_periods=1).mean()\n",
        "\n",
        "    # Lags for target (handled in predict_with_history_buffer dynamically)\n",
        "    # These columns will exist in feature_cols but will be populated during inference\n",
        "\n",
        "    # Interaction features\n",
        "    if \"T_forecast\" in df.columns and \"u_forecast\" in df.columns:\n",
        "        df[\"T_x_u\"] = df[\"T_forecast\"] * df[\"u_forecast\"]\n",
        "    if \"blh_forecast\" in df.columns:\n",
        "        df[\"blh_x_hour_sin\"] = df[\"blh_forecast\"] * df[\"hour_sin\"]\n",
        "        df[\"blh_x_hour_cos\"] = df[\"blh_forecast\"] * df[\"hour_cos\"]\n",
        "\n",
        "    return df\n",
        "\n",
        "# =========================================================\n",
        "# MAIN INFERENCE PIPELINE\n",
        "# =========================================================\n",
        "\n",
        "unseen_path = \"site_4_unseen_input_data.csv\"\n",
        "train_path = \"site_4_train_data.csv\"\n",
        "\n",
        "# 1. Load data\n",
        "df_train = load_site_csv(train_path)\n",
        "df_unseen = load_site_csv(unseen_path)\n",
        "\n",
        "# 2. Build history lookup from training data\n",
        "# Make sure to pass the correct target column if it's not NO2_target.\n",
        "# In our case, the training was for O3_target.\n",
        "# Adjusting build_history_lookup to work for 'O3_target'\n",
        "# For now, let's assume it should build history for O3_target as per training\n",
        "def build_history_lookup_o3(df, target_col='O3_target'):\n",
        "    \"\"\"Create datetime -> target_col lookup.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"BUILDING HISTORY LOOKUP for {target_col}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    if target_col not in df.columns:\n",
        "        print(f\"⚠ {target_col} not found\")\n",
        "        return {}\n",
        "\n",
        "    history_lookup = {}\n",
        "    for idx, row in df.iterrows():\n",
        "        dt = row['datetime']\n",
        "        value = row[target_col]\n",
        "        if pd.notna(value):\n",
        "            history_lookup[dt] = value\n",
        "\n",
        "    print(f\"✓ Built lookup: {len(history_lookup)} entries\")\n",
        "    if history_lookup:\n",
        "        print(f\"  Range: {min(history_lookup.keys())} to {max(history_lookup.keys())}\")\n",
        "\n",
        "    return history_lookup\n",
        "\n",
        "\n",
        "history_lookup = build_history_lookup_o3(df_train, target_col='O3_target')\n",
        "\n",
        "# 3. Feature engineer unseen data\n",
        "df_unseen_eng = create_unseen_features(df_unseen, history_lookup, use_calibrated=True)\n",
        "\n",
        "# 4. Predict using the buffer strategy\n",
        "predictions = predict_with_history_buffer(\n",
        "    df_unseen_eng,\n",
        "    history_lookup,\n",
        "    gru_model,\n",
        "    scaler,\n",
        "    feature_cols,\n",
        "    training_target_median,\n",
        "    column_medians,\n",
        "    seq_len=SEQ_LEN\n",
        ")\n",
        "\n",
        "# 5. Add predictions to DataFrame\n",
        "df_unseen['O3_prediction'] = predictions\n",
        "\n",
        "# Display some results\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"INFERENCE COMPLETE\")\n",
        "print(\"=\"*70)\n",
        "print(df_unseen[['datetime', 'O3_prediction']].head())\n",
        "print(\"...\")\n",
        "print(df_unseen[['datetime', 'O3_prediction']].tail())\n",
        "print(\"=\"*70)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkHBOT6zjls-",
        "outputId": "613dddb1-af7c-49c0-8e0f-c5b5c53ac5f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "LOADING TRAINED MODEL\n",
            "======================================================================\n",
            "✓ Loaded model, scaler, and 30 features\n",
            "✓ Loaded training medians:\n",
            "  - Target median: 31.20\n",
            "  - Column medians: 30 features\n",
            "\n",
            "======================================================================\n",
            "FEATURES REQUIRED (30 total)\n",
            "======================================================================\n",
            "Target-dependent: 11\n",
            "Other features: 19\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "BUILDING HISTORY LOOKUP for O3_target\n",
            "======================================================================\n",
            "✓ Built lookup: 24505 entries\n",
            "  Range: 2019-07-11 00:00:00 to 2024-06-30 00:00:00\n",
            "\n",
            "======================================================================\n",
            "PREDICTING WITH UNIFIED PREPROCESSING\n",
            "======================================================================\n",
            "Using training medians:\n",
            "  Target median: 31.20 µg/m³\n",
            "  Column medians: 30 features\n",
            "\n",
            "Processing 10488 rows...\n",
            "\n",
            "  500/10488 rows...\n",
            "  1000/10488 rows...\n",
            "  1500/10488 rows...\n",
            "  2000/10488 rows...\n",
            "  2500/10488 rows...\n",
            "  3000/10488 rows...\n",
            "  3500/10488 rows...\n",
            "  4000/10488 rows...\n",
            "  4500/10488 rows...\n",
            "  5000/10488 rows...\n",
            "  5500/10488 rows...\n",
            "  6000/10488 rows...\n",
            "  6500/10488 rows...\n",
            "  7000/10488 rows...\n",
            "  7500/10488 rows...\n",
            "  8000/10488 rows...\n",
            "  8500/10488 rows...\n",
            "  9000/10488 rows...\n",
            "  9500/10488 rows...\n",
            "  10000/10488 rows...\n",
            "✓ Completed\n",
            "\n",
            "======================================================================\n",
            "LOOKUP STATISTICS\n",
            "======================================================================\n",
            "  Training data:  160800 ( 61.3%)\n",
            "  Past predictions:  75000 ( 28.6%)\n",
            "  Median-filled:   26400 ( 10.1%)\n",
            "Total lookups: 262200\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "INFERENCE COMPLETE\n",
            "======================================================================\n",
            "             datetime  O3_prediction\n",
            "0 2019-07-25 00:00:00       3.760223\n",
            "1 2019-07-25 01:00:00       7.708520\n",
            "2 2019-07-25 02:00:00      13.507524\n",
            "3 2019-07-25 03:00:00      20.526182\n",
            "4 2019-07-25 04:00:00      27.294067\n",
            "...\n",
            "                 datetime  O3_prediction\n",
            "10483 2024-06-29 19:00:00      43.742203\n",
            "10484 2024-06-29 20:00:00      39.832077\n",
            "10485 2024-06-29 21:00:00      37.036690\n",
            "10486 2024-06-29 22:00:00      34.543068\n",
            "10487 2024-06-29 23:00:00      31.505667\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# SAVE PREDICTIONS TO CSV\n",
        "# =========================================================\n",
        "\n",
        "output_filename = \"unseen_predictions_o3_site4.csv\"\n",
        "\n",
        "# Select only the datetime and prediction columns\n",
        "# Ensure 'datetime' and 'O3_prediction' are the correct column names in your dataframe\n",
        "output_df = df_unseen[['datetime', 'O3_prediction']].copy()\n",
        "\n",
        "# Save to CSV without the pandas index\n",
        "output_df.to_csv(output_filename, index=False)\n",
        "\n",
        "print(f\"\\n✓ Successfully saved predictions to: {output_filename}\")\n",
        "print(f\"  Rows saved: {len(output_df)}\")\n",
        "print(f\"  Columns: {list(output_df.columns)}\")\n",
        "print(\"-\" * 50)\n",
        "print(output_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3BRAMBuxEvV",
        "outputId": "81a73a13-414b-412e-8b6a-2b09447226d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✓ Successfully saved predictions to: unseen_predictions_o3_site4.csv\n",
            "  Rows saved: 10488\n",
            "  Columns: ['datetime', 'O3_prediction']\n",
            "--------------------------------------------------\n",
            "             datetime  O3_prediction\n",
            "0 2019-07-25 00:00:00       3.760223\n",
            "1 2019-07-25 01:00:00       7.708520\n",
            "2 2019-07-25 02:00:00      13.507524\n",
            "3 2019-07-25 03:00:00      20.526182\n",
            "4 2019-07-25 04:00:00      27.294067\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gYZrTziA9s5y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}